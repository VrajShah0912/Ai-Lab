{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8d8a35-8a59-43c4-99e5-f5a148184efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for DFS:  D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS traversal order:\n",
      "D B A C E "
     ]
    }
   ],
   "source": [
    "#(1)Recursive Depth First Search Algorithm\n",
    "\n",
    "import csv\n",
    "\n",
    "# Function to read graph from CSV\n",
    "def read_graph_from_csv(file_path):\n",
    "    graph = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if not row or ',' not in row[0]:\n",
    "                continue\n",
    "            u, v = map(lambda x: x.strip().upper(), row[0].split(','))\n",
    "            graph.setdefault(u, []).append(v)\n",
    "            graph.setdefault(v, []).append(u)\n",
    "    return graph\n",
    "\n",
    "# Recursive DFS\n",
    "def recursive_dfs(graph, node, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(node)\n",
    "    print(node, end=' ')\n",
    "    for neighbor in graph.get(node, []):\n",
    "        if neighbor not in visited:\n",
    "            recursive_dfs(graph, neighbor, visited)\n",
    "\n",
    "# File path\n",
    "file_path = r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\graph.csv\"\n",
    "\n",
    "# Build the graph\n",
    "graph = read_graph_from_csv(file_path)\n",
    "\n",
    "# Input starting node and validate\n",
    "start_node = input(\"Enter the starting node for DFS: \").strip().upper()\n",
    "\n",
    "if start_node not in graph:\n",
    "    print(f\"Error: Node '{start_node}' not found in the graph.\")\n",
    "else:\n",
    "    print(\"DFS traversal order:\")\n",
    "    recursive_dfs(graph, start_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575d7d8-b3d9-4cf2-b5da-15a825c862fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e7324a-2d15-4513-bd58-63efe566ed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter each edge as a pair of nodes (e.g., A B):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " A B\n",
      " B C\n",
      " C D\n",
      " B D\n",
      "Enter the starting node for DFS:  A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS traversal order:\n",
      "A B C D "
     ]
    }
   ],
   "source": [
    "# 2) Non-Recursive DFS for an Undirected Graph\n",
    "\n",
    "def read_graph():\n",
    "    graph = {}\n",
    "    n = int(input(\"Enter number of edges: \"))\n",
    "    print(\"Enter each edge as a pair of nodes (e.g., A B):\")\n",
    "    for _ in range(n):\n",
    "        u, v = input().split()\n",
    "        if u not in graph:\n",
    "            graph[u] = []\n",
    "        if v not in graph:\n",
    "            graph[v] = []\n",
    "        graph[u].append(v)\n",
    "        graph[v].append(u)  # because the graph is undirected\n",
    "    return graph\n",
    "\n",
    "def non_recursive_dfs(graph, start):\n",
    "    visited = set()\n",
    "    stack = [start]\n",
    "\n",
    "    print(\"DFS traversal order:\")\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if node not in visited:\n",
    "            print(node, end=' ')\n",
    "            visited.add(node)\n",
    "            # Add neighbors in reverse sorted order to visit them in lexical order\n",
    "            for neighbor in sorted(graph[node], reverse=True):\n",
    "                if neighbor not in visited:\n",
    "                    stack.append(neighbor)\n",
    "\n",
    "# Example usage\n",
    "graph = read_graph()\n",
    "start_node = input(\"Enter the starting node for DFS: \")\n",
    "non_recursive_dfs(graph, start_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cb9fb-a1d4-4cc0-846e-4b953fe5ce2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d507b3-a073-44c5-a939-09e44a03b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of edges:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter each edge in the format 'node1 node2' (space separated):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " A B\n",
      " B C\n",
      " A D\n",
      " C D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph structure: {'A': ['B', 'D'], 'B': ['A', 'C'], 'C': ['B', 'D'], 'D': ['A', 'C']}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the starting node for BFS:  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BFS traversal order:\n",
      "B A C D "
     ]
    }
   ],
   "source": [
    "# 3) Breadth First Search Algorithm\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Function to read the graph from user\n",
    "def read_graph_from_user():\n",
    "    graph = {}\n",
    "    num_edges = int(input(\"Enter the number of edges: \"))\n",
    "    print(\"Enter each edge in the format 'node1 node2' (space separated):\")\n",
    "    for _ in range(num_edges):\n",
    "        u, v = input().strip().split()\n",
    "        u = u.strip().upper()\n",
    "        v = v.strip().upper()\n",
    "        if u not in graph:\n",
    "            graph[u] = []\n",
    "        if v not in graph:\n",
    "            graph[v] = []\n",
    "        graph[u].append(v)\n",
    "        graph[v].append(u)  # Undirected graph\n",
    "    return graph\n",
    "\n",
    "# BFS Function\n",
    "def bfs(graph, start_node):\n",
    "    visited = set()\n",
    "    queue = deque()\n",
    "\n",
    "    visited.add(start_node)\n",
    "    queue.append(start_node)\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        print(node, end=' ')\n",
    "\n",
    "        for neighbor in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "# Main part\n",
    "graph = read_graph_from_user()\n",
    "print(\"\\nGraph structure:\", graph)\n",
    "\n",
    "start_node = input(\"\\nEnter the starting node for BFS: \").strip().upper()\n",
    "\n",
    "if start_node not in graph:\n",
    "    print(f\"Error: Node '{start_node}' not found in the graph.\")\n",
    "else:\n",
    "    print(\"\\nBFS traversal order:\")\n",
    "    bfs(graph, start_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85521ac-5984-4e0e-8ad4-8af0c2256632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91146e25-7b32-49ad-b23f-64dda3a0dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of edges:  5\n",
      "Enter edge (start end):  A B\n",
      "Enter edge (start end):  A C\n",
      "Enter edge (start end):  B D\n",
      "Enter edge (start end):  C E\n",
      "Enter edge (start end):  D E\n",
      "Enter the number of nodes for heuristics:  5\n",
      "Enter node and heuristic (node h):  A 4\n",
      "Enter node and heuristic (node h):  B 2\n",
      "Enter node and heuristic (node h):  C 3\n",
      "Enter node and heuristic (node h):  D 1\n",
      "Enter node and heuristic (node h):  E 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph structure: {'A': ['B', 'C'], 'B': ['D'], 'C': ['E'], 'D': ['E']}\n",
      "Heuristic values: {'A': 4, 'B': 2, 'C': 3, 'D': 1, 'E': 0}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the starting node:  A\n",
      "Enter the goal node:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best First Search traversal order:\n",
      "A B D E \n",
      "Goal node reached!\n"
     ]
    }
   ],
   "source": [
    "# 4) Best FS  Algo - Directed|UnWeighted\n",
    "\n",
    "import heapq\n",
    "\n",
    "def read_graph_from_user():\n",
    "    graph = {}\n",
    "    for _ in range(int(input(\"Enter the number of edges: \"))):\n",
    "        u, v = input(\"Enter edge (start end): \").strip().upper().split()\n",
    "        graph.setdefault(u, []).append(v)\n",
    "    return graph\n",
    "\n",
    "def read_heuristics():\n",
    "    heuristics = {}\n",
    "    for _ in range(int(input(\"Enter the number of nodes for heuristics: \"))):\n",
    "        node, h = input(\"Enter node and heuristic (node h): \").strip().upper().split()\n",
    "        heuristics[node] = int(h)\n",
    "    return heuristics\n",
    "\n",
    "def best_first_search(graph, heuristics, start, goal):\n",
    "    visited = set()\n",
    "    queue = [(heuristics[start], start)]\n",
    "\n",
    "    while queue:\n",
    "        _, node = heapq.heappop(queue)\n",
    "        if node in visited:\n",
    "            continue\n",
    "        print(node, end=' ')\n",
    "        visited.add(node)\n",
    "        if node == goal:\n",
    "            print(\"\\nGoal node reached!\")\n",
    "            return\n",
    "        for neighbor in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                heapq.heappush(queue, (heuristics[neighbor], neighbor))\n",
    "    \n",
    "    print(\"\\nGoal node not reachable.\")\n",
    "\n",
    "# Main\n",
    "graph = read_graph_from_user()\n",
    "heuristics = read_heuristics()\n",
    "\n",
    "print(\"\\nGraph structure:\", graph)\n",
    "print(\"Heuristic values:\", heuristics)\n",
    "\n",
    "start = input(\"\\nEnter the starting node: \").strip().upper()\n",
    "goal = input(\"Enter the goal node: \").strip().upper()\n",
    "\n",
    "if start not in graph:\n",
    "    print(f\"Error: Start node '{start}' not found in graph.\")\n",
    "elif goal not in heuristics:\n",
    "    print(f\"Error: Goal node '{goal}' not found in heuristic values.\")\n",
    "else:\n",
    "    print(\"\\nBest First Search traversal order:\")\n",
    "    best_first_search(graph, heuristics, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c87ca9-a016-4486-9614-cad23dd1b452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b472e6b-2898-49fa-b064-713e121130e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of edges:  5\n",
      "Edge (u v weight):  A B 4\n",
      "Edge (u v weight):  A C 2\n",
      "Edge (u v weight):  B D 5\n",
      "Edge (u v weight):  C D 8\n",
      "Edge (u v weight):  C E 10\n",
      "Enter number of nodes:  6\n",
      "Node and Heuristic (node h):  A 7\n",
      "Node and Heuristic (node h):  B 6\n",
      "Node and Heuristic (node h):  C 2\n",
      "Node and Heuristic (node h):  D 1\n",
      "Node and Heuristic (node h):  E 0\n",
      "Node and Heuristic (node h):  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Main\u001b[39;00m\n\u001b[32m     35\u001b[39m graph = read_graph()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m heuristics = \u001b[43mread_heuristics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m start, goal = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStart node: \u001b[39m\u001b[33m\"\u001b[39m).strip().upper(), \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGoal node: \u001b[39m\u001b[33m\"\u001b[39m).strip().upper()\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest First Search Traversal:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mread_heuristics\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_heuristics\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNode and Heuristic (node h): \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnter number of nodes: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_heuristics\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {node.upper(): \u001b[38;5;28mint\u001b[39m(h) \u001b[38;5;28;01mfor\u001b[39;00m node, h \u001b[38;5;129;01min\u001b[39;00m \n\u001b[32m     16\u001b[39m             (\u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNode and Heuristic (node h): \u001b[39m\u001b[33m\"\u001b[39m).split() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter number of nodes: \u001b[39m\u001b[33m\"\u001b[39m))))}\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "# 5) Best FS  Algo - Directed|Weighted\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Read graph\n",
    "def read_graph():\n",
    "    graph = {}\n",
    "    for _ in range(int(input(\"Enter number of edges: \"))):\n",
    "        u, v, w = input(\"Edge (u v weight): \").upper().split()\n",
    "        graph.setdefault(u, []).append((v, int(w)))\n",
    "    return graph\n",
    "\n",
    "# Read heuristics\n",
    "def read_heuristics():\n",
    "    return {node.upper(): int(h) for node, h in \n",
    "            (input(\"Node and Heuristic (node h): \").split() for _ in range(int(input(\"Enter number of nodes: \"))))}\n",
    "\n",
    "# Best First Search\n",
    "def best_first_search(graph, heuristics, start, goal):\n",
    "    visited, queue = set(), [(heuristics[start], start)]\n",
    "    while queue:\n",
    "        _, node = heapq.heappop(queue)\n",
    "        if node in visited: continue\n",
    "        print(node, end=' ')\n",
    "        visited.add(node)\n",
    "        if node == goal:\n",
    "            print(\"\\nGoal reached!\")\n",
    "            return\n",
    "        for neighbor, _ in graph.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                heapq.heappush(queue, (heuristics[neighbor], neighbor))\n",
    "    print(\"\\nGoal not reachable.\")\n",
    "\n",
    "# Main\n",
    "graph = read_graph()\n",
    "heuristics = read_heuristics()\n",
    "start, goal = input(\"Start node: \").strip().upper(), input(\"Goal node: \").strip().upper()\n",
    "\n",
    "print(\"\\nBest First Search Traversal:\")\n",
    "best_first_search(graph, heuristics, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090533f-1772-4837-9255-ef39437fcaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "296a4ece-fe08-437d-b423-b2a5c12e97a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Edges:  5\n",
      " A B 4\n",
      " A C 2\n",
      " B D 5\n",
      " C D 8\n",
      " C E 10\n",
      "Nodes:  5\n",
      "Node Heuristic:  A 7\n",
      "Node Heuristic:  B 6\n",
      "Node Heuristic:  C 2\n",
      "Node Heuristic:  D 1\n",
      "Node Heuristic:  E 0\n",
      "Start:  A\n",
      "Goal:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best First Search Traversal:\n",
      "A C E \n",
      "Goal reached!\n"
     ]
    }
   ],
   "source": [
    "# 6) Best FS Algo - undirected|weighted\n",
    "\n",
    "import heapq\n",
    "\n",
    "def read_graph():\n",
    "    g = {}\n",
    "    for _ in range(int(input(\"Edges: \"))):\n",
    "        u, v, w = input().upper().split()\n",
    "        g.setdefault(u, []).append((v, int(w)))\n",
    "        g.setdefault(v, []).append((u, int(w)))\n",
    "    return g\n",
    "\n",
    "def read_heuristics():\n",
    "    return {node.upper(): int(h) for node, h in \n",
    "            (input(\"Node Heuristic: \").split() for _ in range(int(input(\"Nodes: \"))))}\n",
    "\n",
    "def best_first_search(g, h, start, goal):\n",
    "    visited, q = set(), [(h[start], start)]\n",
    "    while q:\n",
    "        _, node = heapq.heappop(q)\n",
    "        if node in visited: continue\n",
    "        print(node, end=' ')\n",
    "        if node == goal:\n",
    "            print(\"\\nGoal reached!\")\n",
    "            return\n",
    "        visited.add(node)\n",
    "        for neighbor, _ in g.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                heapq.heappush(q, (h[neighbor], neighbor))\n",
    "    print(\"\\nGoal not reachable.\")\n",
    "\n",
    "g = read_graph()\n",
    "h = read_heuristics()\n",
    "start, goal = input(\"Start: \").upper(), input(\"Goal: \").upper()\n",
    "print(\"\\nBest First Search Traversal:\")\n",
    "best_first_search(g, h, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a87427-8a3d-4afa-bc87-1f7cdf884790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5845c38a-15b3-434a-9c0e-5e7001bb7009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Edges:  5\n",
      "Edge (u v):  A B\n",
      "Edge (u v):  A C\n",
      "Edge (u v):  B D\n",
      "Edge (u v):  C D\n",
      "Edge (u v):  C E\n",
      "Nodes:  5\n",
      "Node Heuristic:  A 7\n",
      "Node Heuristic:  B 6\n",
      "Node Heuristic:  C 2\n",
      "Node Heuristic:  D 1\n",
      "Node Heuristic:  E 0\n",
      "Start:  A \n",
      "Goal:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best First Search Traversal:\n",
      "A C E \n",
      "Goal reached!\n"
     ]
    }
   ],
   "source": [
    "# 7) Best FS Algo - undirected| Unweighted\n",
    "\n",
    "import heapq\n",
    "\n",
    "def read_graph():\n",
    "    g = {}\n",
    "    for _ in range(int(input(\"Edges: \"))):\n",
    "        u, v = input(\"Edge (u v): \").upper().split()\n",
    "        g.setdefault(u, []).append(v)\n",
    "        g.setdefault(v, []).append(u)\n",
    "    return g\n",
    "\n",
    "def read_heuristics():\n",
    "    return {node.upper(): int(h) for node, h in \n",
    "            (input(\"Node Heuristic: \").split() for _ in range(int(input(\"Nodes: \"))))}\n",
    "\n",
    "def best_first_search(g, h, start, goal):\n",
    "    visited, q = set(), [(h[start], start)]\n",
    "    while q:\n",
    "        _, node = heapq.heappop(q)\n",
    "        if node in visited: continue\n",
    "        print(node, end=' ')\n",
    "        if node == goal:\n",
    "            print(\"\\nGoal reached!\")\n",
    "            return\n",
    "        visited.add(node)\n",
    "        for neighbor in g.get(node, []):\n",
    "            if neighbor not in visited:\n",
    "                heapq.heappush(q, (h[neighbor], neighbor))\n",
    "    print(\"\\nGoal not reachable.\")\n",
    "\n",
    "g = read_graph()\n",
    "h = read_heuristics()\n",
    "start, goal = input(\"Start: \").strip().upper(), input(\"Goal: \").strip().upper()\n",
    "print(\"\\nBest First Search Traversal:\")\n",
    "best_first_search(g, h, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850cc596-fffa-4ba7-a125-85c79c1452a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ad508e-e189-43e4-85be-f90630b4abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter start node:  B \n",
      "Enter goal node:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A* Traversal:\n",
      "B D E \n",
      "Goal reached!\n"
     ]
    }
   ],
   "source": [
    "# 8)A* Algo - Directed|Weighted from CSV\n",
    "\n",
    "import csv, heapq\n",
    "\n",
    "def read_graph_and_heuristics(path):\n",
    "    g, h = {}, {}\n",
    "    with open(path) as f:\n",
    "        next(f)\n",
    "        for row in csv.reader(f):\n",
    "            row = [x.strip() for x in row if x.strip() != '']  # Clean empty cells\n",
    "            if not row:\n",
    "                continue\n",
    "            if len(row) == 3:\n",
    "                u, v, w = row[0].upper(), row[1].upper(), int(row[2])\n",
    "                g.setdefault(u, []).append((v, w))\n",
    "            elif len(row) == 2:\n",
    "                node, heur = row[0].upper(), int(row[1])\n",
    "                h[node] = heur\n",
    "    return g, h\n",
    "\n",
    "def a_star(g, h, start, goal):\n",
    "    queue, visited = [(h.get(start, 0), 0, start)], set()\n",
    "    while queue:\n",
    "        _, g_val, node = heapq.heappop(queue)\n",
    "        if node in visited: continue\n",
    "        print(node, end=' ')\n",
    "        if node == goal: return print(\"\\nGoal reached!\")\n",
    "        visited.add(node)\n",
    "        for nei, cost in g.get(node, []):\n",
    "            if nei not in visited:\n",
    "                heapq.heappush(queue, (g_val + cost + h.get(nei, 0), g_val + cost, nei))\n",
    "    print(\"\\nGoal not reachable.\")\n",
    "\n",
    "# Main\n",
    "path = r\"C:\\Users\\Vraj Shah\\Downloads\\sample_graph_exp 8.csv\"  # Your CSV path\n",
    "graph, heuristics = read_graph_and_heuristics(path)\n",
    "\n",
    "start = input(\"Enter start node: \").strip().upper()\n",
    "goal = input(\"Enter goal node: \").strip().upper()\n",
    "\n",
    "print(\"\\nA* Traversal:\")\n",
    "a_star(graph, heuristics, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ba4ea-1d95-4f85-a9ad-1f186315301f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b72a44-f05f-4013-af86-a55c4459c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Edges?  5\n",
      "From, To, Weight:  A B 1\n",
      "From, To, Weight:  A C 3\n",
      "From, To, Weight:  B D 1\n",
      "From, To, Weight:  C D 1\n",
      "From, To, Weight:  D E 5\n",
      "Nodes?  5\n",
      "Node:  A 7\n",
      "Heuristic:  7\n",
      "Node:  B\n",
      "Heuristic:  6\n",
      "Node:  C\n",
      "Heuristic:  2\n",
      "Node:  D\n",
      "Heuristic:  1\n",
      "Node:  E\n",
      "Heuristic:  0\n",
      "Start:  A\n",
      "Goal:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A* Traversal:\n",
      "A C D B E \n",
      "Goal reached!\n"
     ]
    }
   ],
   "source": [
    "# 9) A* algo - Directed|Weighted from User\n",
    "\n",
    "import heapq\n",
    "\n",
    "def read_graph(): \n",
    "    g = {}; n = int(input(\"Edges? \"))\n",
    "    for _ in range(n):\n",
    "        u, v, w = input(\"From, To, Weight: \").upper().split()\n",
    "        g.setdefault(u, []).append((v, int(w)))\n",
    "    return g\n",
    "\n",
    "def read_heuristics():\n",
    "    return {input(\"Node: \").upper(): int(input(\"Heuristic: \")) for _ in range(int(input(\"Nodes? \")))}\n",
    "\n",
    "def a_star(g, h, start, goal):\n",
    "    q, v = [(h.get(start, 0), 0, start)], set()\n",
    "    while q:\n",
    "        _, g_val, node = heapq.heappop(q)\n",
    "        if node in v: continue\n",
    "        print(node, end=' ')\n",
    "        if node == goal: return print(\"\\nGoal reached!\")\n",
    "        v.add(node)\n",
    "        for nei, cost in g.get(node, []):\n",
    "            if nei not in v:\n",
    "                heapq.heappush(q, (g_val + cost + h.get(nei, 0), g_val + cost, nei))\n",
    "    print(\"\\nGoal not reachable.\")\n",
    "\n",
    "# Main\n",
    "g, h = read_graph(), read_heuristics()\n",
    "start, goal = input(\"Start: \").upper(), input(\"Goal: \").upper()\n",
    "\n",
    "print(\"\\nA* Traversal:\")\n",
    "a_star(g, h, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f006d-c22a-4136-81cd-f6da023f7b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603bbd77-5232-4eb5-a849-db23bd49a0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter start node:  A\n",
      "Enter goal node:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A* Traversal:\n",
      "A C D B E \n",
      "Goal reached!\n"
     ]
    }
   ],
   "source": [
    "# 10)A* Algo - Undirected|Weighted from CSV\n",
    "\n",
    "import csv, heapq\n",
    "\n",
    "def read_graph_heuristics(file):\n",
    "    g, h = {}, {}\n",
    "    with open(file) as f:\n",
    "        for r in csv.DictReader(f):\n",
    "            u = r['From'].strip().upper()\n",
    "            if r['Heuristic']: h[u] = int(r['Heuristic'])\n",
    "            if r['To']:\n",
    "                v, w = r['To'].strip().upper(), int(r['Weight'])\n",
    "                g.setdefault(u, []).append((v, w))\n",
    "                g.setdefault(v, []).append((u, w))  # Undirected\n",
    "    return g, h\n",
    "\n",
    "def astar(g, h, start, goal):\n",
    "    q, seen = [(h.get(start, 0), 0, start)], set()\n",
    "    while q:\n",
    "        _, g_val, u = heapq.heappop(q)\n",
    "        if u in seen: continue\n",
    "        print(u, end=' ')\n",
    "        if u == goal: return print(\"\\nGoal reached!\")\n",
    "        seen.add(u)\n",
    "        for v, cost in g.get(u, []):\n",
    "            if v not in seen:\n",
    "                heapq.heappush(q, (g_val + cost + h.get(v, 0), g_val + cost, v))\n",
    "    print(\"\\nGoal not reachable.\")\n",
    "\n",
    "# === Main ===\n",
    "file = r\"C:\\Users\\Vraj Shah\\Downloads\\sample_astar_graph_exp 10.csv\" # <- Put your file path here!\n",
    "g, h = read_graph_heuristics(file)\n",
    "start = input(\"Enter start node: \").strip().upper()\n",
    "goal = input(\"Enter goal node: \").strip().upper()\n",
    "\n",
    "print(\"\\nA* Traversal:\")\n",
    "astar(g, h, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45b278f-2978-47bd-84e4-5ce51444ef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5e1aa3-917f-44ea-9028-c0cfda1e536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Edges:  5\n",
      "From:  A\n",
      "To:  B\n",
      "Weight:  1\n",
      "From:  A\n",
      "To:  C\n",
      "Weight:  3\n",
      "From:  B\n",
      "To:  D\n",
      "Weight:  1\n",
      "From:  C\n",
      "To:  D\n",
      "Weight:  1\n",
      "From:  D\n",
      "To:  E\n",
      "Weight:  5\n",
      "Heuristic nodes:  5\n",
      "Node:  A\n",
      "Heuristic A:  7\n",
      "Node:  B\n",
      "Heuristic B:  6\n",
      "Node:  C\n",
      "Heuristic C:  2\n",
      "Node:  D\n",
      "Heuristic D:  1\n",
      "Node:  E\n",
      "Heuristic E:  0\n",
      "Start:  A\n",
      "Goal:  E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A* Traversal:\n",
      "A C D B E \n",
      "Goal reached!\n"
     ]
    }
   ],
   "source": [
    "# 11) A* Algo -  Undirected|Weighted from User\n",
    "\n",
    "import heapq\n",
    "\n",
    "g, h = {}, {}\n",
    "for _ in range(int(input(\"Edges: \"))):\n",
    "    u, v, w = input(\"From: \").upper(), input(\"To: \").upper(), int(input(\"Weight: \"))\n",
    "    g.setdefault(u, []).append((v, w))\n",
    "    g.setdefault(v, []).append((u, w))\n",
    "\n",
    "for _ in range(int(input(\"Heuristic nodes: \"))):\n",
    "    n = input(\"Node: \").upper()\n",
    "    h[n] = int(input(f\"Heuristic {n}: \"))\n",
    "\n",
    "def astar(g, h, start, goal):\n",
    "    q, seen = [(h.get(start,0), 0, start)], set()\n",
    "    while q:\n",
    "        _, gval, u = heapq.heappop(q)\n",
    "        if u in seen: continue\n",
    "        print(u, end=' ')\n",
    "        if u == goal: return print(\"\\nGoal reached!\")\n",
    "        seen.add(u)\n",
    "        for v, cost in g.get(u, []):\n",
    "            if v not in seen:\n",
    "                heapq.heappush(q, (gval+cost+h.get(v,0), gval+cost, v))\n",
    "    print(\"\\nGoal not reachable.\")\n",
    "\n",
    "start = input(\"Start: \").strip().upper()\n",
    "goal = input(\"Goal: \").strip().upper()\n",
    "print(\"\\nA* Traversal:\")\n",
    "astar(g, h, start, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04a7ae-4aac-4da5-8415-a9074ceb4782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed5c91f-f6f1-4fca-8de5-4d3020677532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Union of A and B:\n",
      "y: 0.5\n",
      "x: 0.6\n",
      "z: 0.8\n",
      "\n",
      "Intersection of B and C:\n",
      "y: 0.4\n",
      "x: 0.6\n",
      "z: 0.1\n",
      "\n",
      "Complement of C:\n",
      "x: 0.1\n",
      "y: 0.3\n",
      "z: 0.9\n"
     ]
    }
   ],
   "source": [
    "# 12) Implement Fuzzy set operations -Demonstrate these operations with 3 fuzzy sets. \n",
    "\n",
    "# Define 3 fuzzy sets\n",
    "A = {'x': 0.2, 'y': 0.5, 'z': 0.8}\n",
    "B = {'x': 0.6, 'y': 0.4, 'z': 0.3}\n",
    "C = {'x': 0.9, 'y': 0.7, 'z': 0.1}\n",
    "\n",
    "# Union of two fuzzy sets\n",
    "def fuzzy_union(set1, set2):\n",
    "    return {k: max(set1.get(k,0), set2.get(k,0)) for k in set(set1) | set(set2)}\n",
    "\n",
    "# Intersection of two fuzzy sets\n",
    "def fuzzy_intersection(set1, set2):\n",
    "    return {k: min(set1.get(k,0), set2.get(k,0)) for k in set(set1) | set(set2)}\n",
    "\n",
    "# Complement of a fuzzy set\n",
    "def fuzzy_complement(set1):\n",
    "    return {k: round(1 - v, 2) for k, v in set1.items()}\n",
    "\n",
    "# Display function\n",
    "def display(title, fz_set):\n",
    "    print(f\"\\n{title}:\")\n",
    "    for k, v in fz_set.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "# Perform operations\n",
    "union_AB = fuzzy_union(A, B)\n",
    "intersection_BC = fuzzy_intersection(B, C)\n",
    "complement_C = fuzzy_complement(C)\n",
    "\n",
    "# Display results\n",
    "display(\"Union of A and B\", union_AB)\n",
    "display(\"Intersection of B and C\", intersection_BC)\n",
    "display(\"Complement of C\", complement_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45c28d-1b05-4365-a1fe-929baf7df12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2769e01d-fbfc-44ab-b01e-1e3b0f8efe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set A:\n",
      "x: 0.3\n",
      "y: 0.6\n",
      "z: 0.8\n",
      "\n",
      "Set B:\n",
      "x: 0.7\n",
      "y: 0.4\n",
      "z: 0.5\n",
      "\n",
      "Union of A and B:\n",
      "y: 0.6\n",
      "x: 0.7\n",
      "z: 0.8\n",
      "\n",
      "Complement of (A ∪ B):\n",
      "y: 0.4\n",
      "x: 0.3\n",
      "z: 0.2\n",
      "\n",
      "Complement of A:\n",
      "x: 0.7\n",
      "y: 0.4\n",
      "z: 0.2\n",
      "\n",
      "Complement of B:\n",
      "x: 0.3\n",
      "y: 0.6\n",
      "z: 0.5\n",
      "\n",
      "Intersection of complements (¬A ∩ ¬B):\n",
      "y: 0.4\n",
      "x: 0.3\n",
      "z: 0.2\n",
      "\n",
      "De Morgan's Law Verified: True\n"
     ]
    }
   ],
   "source": [
    "# 13) Demonstrate De Morgan’s Law ( Complement of Union) with 2 fuzzy sets. \n",
    "\n",
    "# Define 2 fuzzy sets\n",
    "A = {'x': 0.3, 'y': 0.6, 'z': 0.8}\n",
    "B = {'x': 0.7, 'y': 0.4, 'z': 0.5}\n",
    "\n",
    "# Fuzzy Operations\n",
    "def fuzzy_union(set1, set2):\n",
    "    return {k: max(set1.get(k,0), set2.get(k,0)) for k in set(set1) | set(set2)}\n",
    "\n",
    "def fuzzy_intersection(set1, set2):\n",
    "    return {k: min(set1.get(k,0), set2.get(k,0)) for k in set(set1) | set(set2)}\n",
    "\n",
    "def fuzzy_complement(set1):\n",
    "    return {k: round(1 - v, 2) for k, v in set1.items()}\n",
    "\n",
    "def display(title, fz_set):\n",
    "    print(f\"\\n{title}:\")\n",
    "    for k, v in fz_set.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "# Operations\n",
    "union_AB = fuzzy_union(A, B)\n",
    "complement_union = fuzzy_complement(union_AB)\n",
    "\n",
    "complement_A = fuzzy_complement(A)\n",
    "complement_B = fuzzy_complement(B)\n",
    "intersection_complements = fuzzy_intersection(complement_A, complement_B)\n",
    "\n",
    "# Display\n",
    "display(\"Set A\", A)\n",
    "display(\"Set B\", B)\n",
    "display(\"Union of A and B\", union_AB)\n",
    "display(\"Complement of (A ∪ B)\", complement_union)\n",
    "display(\"Complement of A\", complement_A)\n",
    "display(\"Complement of B\", complement_B)\n",
    "display(\"Intersection of complements (¬A ∩ ¬B)\", intersection_complements)\n",
    "\n",
    "# Verify De Morgan's Law\n",
    "print(\"\\nDe Morgan's Law Verified:\", complement_union == intersection_complements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a4197-4397-497f-a305-51c68e24eb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7545254-6d91-43e1-bbb8-fcbcccc9a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set A: {'x1': 0.2, 'x2': 0.7, 'x3': 1.0}\n",
      "Set B: {'x1': 0.5, 'x2': 0.4, 'x3': 0.9}\n",
      "\n",
      "Union (A ∪ B): {'x1': 0.5, 'x3': 1.0, 'x2': 0.7}\n",
      "Intersection (A ∩ B): {'x1': 0.2, 'x3': 0.9, 'x2': 0.4}\n",
      "Complement of A (A'): {'x1': 0.8, 'x2': 0.30000000000000004, 'x3': 0.0}\n",
      "Complement of B (B'): {'x1': 0.5, 'x2': 0.6, 'x3': 0.09999999999999998}\n",
      "\n",
      "Complement of (A ∩ B): {'x1': 0.8, 'x3': 0.09999999999999998, 'x2': 0.6}\n",
      "Union of (A' ∪ B'): {'x1': 0.8, 'x3': 0.09999999999999998, 'x2': 0.6}\n",
      "\n",
      " De Morgan's Law Verified!\n"
     ]
    }
   ],
   "source": [
    "# Fuzzy Set Operations (Short Version)\n",
    "\n",
    "A = {'x1': 0.2, 'x2': 0.7, 'x3': 1.0}\n",
    "B = {'x1': 0.5, 'x2': 0.4, 'x3': 0.9}\n",
    "\n",
    "print(\"Set A:\", A)\n",
    "print(\"Set B:\", B)\n",
    "\n",
    "# Operations\n",
    "union = {x: max(A.get(x, 0), B.get(x, 0)) for x in set(A) | set(B)}\n",
    "intersection = {x: min(A.get(x, 0), B.get(x, 0)) for x in set(A) | set(B)}\n",
    "complement_A = {x: 1 - A[x] for x in A}\n",
    "complement_B = {x: 1 - B[x] for x in B}\n",
    "\n",
    "print(\"\\nUnion (A ∪ B):\", union)\n",
    "print(\"Intersection (A ∩ B):\", intersection)\n",
    "print(\"Complement of A (A'):\", complement_A)\n",
    "print(\"Complement of B (B'):\", complement_B)\n",
    "\n",
    "# De Morgan's Law\n",
    "comp_intersection = {x: 1 - intersection[x] for x in intersection}\n",
    "union_complements = {x: max(complement_A.get(x, 0), complement_B.get(x, 0)) for x in set(complement_A) | set(complement_B)}\n",
    "\n",
    "print(\"\\nComplement of (A ∩ B):\", comp_intersection)\n",
    "print(\"Union of (A' ∪ B'):\", union_complements)\n",
    "\n",
    "print(\"\\n De Morgan's Law Verified!\" if comp_intersection == union_complements else \"\\n❌ De Morgan's Law Failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196200ae-27c0-4bc1-9bf5-acc6bcd4fe24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ca8909-000a-4b81-95d7-9350d9d55fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Modified Tic-Tac-Toe!\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  0 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | X |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "\n",
      "Computer's move:\n",
      "O | X |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O | X |  \n",
      "-----\n",
      "  | X |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "\n",
      "Computer's move:\n",
      "O | X |  \n",
      "-----\n",
      "  | X |  \n",
      "-----\n",
      "  | O |  \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  1 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O | X |  \n",
      "-----\n",
      "X | X |  \n",
      "-----\n",
      "  | O |  \n",
      "-----\n",
      "\n",
      "Computer's move:\n",
      "O | X |  \n",
      "-----\n",
      "X | X | O\n",
      "-----\n",
      "  | O |  \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  2 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid move! Cell occupied.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  2 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O | X |  \n",
      "-----\n",
      "X | X | O\n",
      "-----\n",
      "X | O |  \n",
      "-----\n",
      "\n",
      "Computer's move:\n",
      "O | X | O\n",
      "-----\n",
      "X | X | O\n",
      "-----\n",
      "X | O |  \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  2 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O | X | O\n",
      "-----\n",
      "X | X | O\n",
      "-----\n",
      "X | O | X\n",
      "-----\n",
      "\n",
      "Result: Draw\n"
     ]
    }
   ],
   "source": [
    "# 15) Modified Tic-Tac-Toe, using min-max algorithm such that in every play either computer wins or it is a draw. \n",
    "\n",
    "# Modified Tic-Tac-Toe (Minimax AI)\n",
    "\n",
    "import math\n",
    "\n",
    "def print_board(board):\n",
    "    for row in board:\n",
    "        print(\" | \".join(row))\n",
    "        print(\"-\" * 5)\n",
    "\n",
    "def check_winner(board):\n",
    "    for line in board + list(zip(*board)) + [[board[i][i] for i in range(3)], [board[i][2-i] for i in range(3)]]:\n",
    "        if all(cell == 'X' for cell in line):\n",
    "            return 'X'\n",
    "        if all(cell == 'O' for cell in line):\n",
    "            return 'O'\n",
    "    return None if any(cell == ' ' for row in board for cell in row) else 'Draw'\n",
    "\n",
    "def minimax(board, is_maximizing):\n",
    "    winner = check_winner(board)\n",
    "    if winner == 'O': return 1\n",
    "    if winner == 'X': return -1\n",
    "    if winner == 'Draw': return 0\n",
    "\n",
    "    best_score = -math.inf if is_maximizing else math.inf\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if board[i][j] == ' ':\n",
    "                board[i][j] = 'O' if is_maximizing else 'X'\n",
    "                score = minimax(board, not is_maximizing)\n",
    "                board[i][j] = ' '\n",
    "                best_score = max(score, best_score) if is_maximizing else min(score, best_score)\n",
    "\n",
    "    return best_score\n",
    "\n",
    "def best_move(board):\n",
    "    move = None\n",
    "    best_score = -math.inf\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if board[i][j] == ' ':\n",
    "                board[i][j] = 'O'\n",
    "                score = minimax(board, False)\n",
    "                board[i][j] = ' '\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    move = (i, j)\n",
    "    return move\n",
    "\n",
    "# Main Game Loop\n",
    "board = [[' ']*3 for _ in range(3)]\n",
    "\n",
    "print(\"Welcome to Modified Tic-Tac-Toe!\")\n",
    "print_board(board)\n",
    "\n",
    "while True:\n",
    "    # Player move\n",
    "    try:\n",
    "        row, col = map(int, input(\"\\nEnter your move (row and column 0-2): \").split())\n",
    "        if board[row][col] != ' ':\n",
    "            print(\"Invalid move! Cell occupied.\")\n",
    "            continue\n",
    "        board[row][col] = 'X'\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"Invalid input! Enter row and column between 0-2.\")\n",
    "        continue\n",
    "\n",
    "    print_board(board)\n",
    "    if (result := check_winner(board)):\n",
    "        print(\"\\nResult:\", result)\n",
    "        break\n",
    "\n",
    "    # Computer move\n",
    "    i, j = best_move(board)\n",
    "    board[i][j] = 'O'\n",
    "    print(\"\\nComputer's move:\")\n",
    "    print_board(board)\n",
    "\n",
    "    if (result := check_winner(board)):\n",
    "        print(\"\\nResult:\", result)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d548d63-976d-4d3d-ac48-608281cf82b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5be1d10-27f6-4b08-85b4-bbbbddd62085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Modified Tic-Tac-Toe (Computer loses or draws)!\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "\n",
      "Computer's move:\n",
      "X |   |  \n",
      "-----\n",
      "  |   |  \n",
      "-----\n",
      "  |   | O\n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  1 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X |   |  \n",
      "-----\n",
      "X |   |  \n",
      "-----\n",
      "  |   | O\n",
      "-----\n",
      "\n",
      "Computer's move:\n",
      "X |   |  \n",
      "-----\n",
      "X |   |  \n",
      "-----\n",
      "  | O | O\n",
      "-----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (row and column 0-2):  2 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X |   |  \n",
      "-----\n",
      "X |   |  \n",
      "-----\n",
      "X | O | O\n",
      "-----\n",
      "\n",
      "Result: X\n"
     ]
    }
   ],
   "source": [
    "# 16) Modified Tic-Tac-Toe (Bad Minimax AI - computer loses or draws)\n",
    "\n",
    "import random\n",
    "\n",
    "def print_board(board):\n",
    "    for row in board:\n",
    "        print(\" | \".join(row))\n",
    "        print(\"-\" * 5)\n",
    "\n",
    "def check_winner(board):\n",
    "    lines = board + list(zip(*board)) + [[board[i][i] for i in range(3)], [board[i][2-i] for i in range(3)]]\n",
    "    for line in lines:\n",
    "        if all(cell == 'X' for cell in line):\n",
    "            return 'X'\n",
    "        if all(cell == 'O' for cell in line):\n",
    "            return 'O'\n",
    "    return None if any(cell == ' ' for row in board for cell in row) else 'Draw'\n",
    "\n",
    "# BAD Minimax: Computer makes random valid moves\n",
    "def bad_move(board):\n",
    "    empty = [(i, j) for i in range(3) for j in range(3) if board[i][j] == ' ']\n",
    "    return random.choice(empty) if empty else None\n",
    "\n",
    "# Main Game\n",
    "board = [[' ']*3 for _ in range(3)]\n",
    "\n",
    "print(\"Welcome to Modified Tic-Tac-Toe (Computer loses or draws)!\")\n",
    "print_board(board)\n",
    "\n",
    "while True:\n",
    "    # Player move\n",
    "    try:\n",
    "        row, col = map(int, input(\"\\nEnter your move (row and column 0-2): \").split())\n",
    "        if board[row][col] != ' ':\n",
    "            print(\"Invalid move! Cell occupied.\")\n",
    "            continue\n",
    "        board[row][col] = 'X'\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"Invalid input! Enter row and column between 0-2.\")\n",
    "        continue\n",
    "\n",
    "    print_board(board)\n",
    "    if (result := check_winner(board)):\n",
    "        print(\"\\nResult:\", result)\n",
    "        break\n",
    "\n",
    "    # Computer bad move\n",
    "    move = bad_move(board)\n",
    "    if move:\n",
    "        i, j = move\n",
    "        board[i][j] = 'O'\n",
    "        print(\"\\nComputer's move:\")\n",
    "        print_board(board)\n",
    "\n",
    "    if (result := check_winner(board)):\n",
    "        print(\"\\nResult:\", result)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea6c8e7e-f984-464e-9ff7-af096046e8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.5-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.2.5-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 1.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 2.3 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/12.9 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 3.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/12.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.0/12.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.9 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.9 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.9/12.9 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/12.9 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a238ed0f-0533-44ab-a703-1d31aa2bea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights and Biases after training:\n",
      "\n",
      "w1 (Input -> Hidden Layer 1):\n",
      "[[-2.57296726 -1.16195394 -1.24619125  1.56044297]\n",
      " [-1.45014009 -1.01497243  0.36655751  1.0520165 ]\n",
      " [ 1.67872779  1.66337222  0.7076231  -0.46982726]\n",
      " [-0.58687204 -1.13209812 -0.92408676  0.04146198]]\n",
      "\n",
      "b1 (Hidden Layer 1 bias):\n",
      "[[ 1.51943786  0.27670271 -0.82791378 -0.57839982]]\n",
      "\n",
      "w2 (Hidden Layer 1 -> Hidden Layer 2):\n",
      "[[ 2.14677822 -3.31033303  1.82798977 -1.56332285]\n",
      " [ 1.56195019 -1.55493669  0.88293082 -1.08152898]\n",
      " [ 1.11354177 -0.4782022   0.29751993 -0.67947616]\n",
      " [-1.29374078  2.05730494 -0.09479226  1.3694023 ]]\n",
      "\n",
      "b2 (Hidden Layer 2 bias):\n",
      "[[-0.77978391  0.65028917 -0.67188915  0.02363514]]\n",
      "\n",
      "w3 (Hidden Layer 2 -> Output):\n",
      "[[-3.33091157]\n",
      " [ 4.72217687]\n",
      " [-2.11899715]\n",
      " [ 2.35861003]]\n",
      "\n",
      "b3 (Output bias):\n",
      "[[-0.28992238]]\n",
      "\n",
      "Total number of steps taken: 10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function: Sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of Sigmoid (for backpropagation)\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Function to create a simple MLP\n",
    "def simple_mlp(N, max_steps=10000, learning_rate=0.1):\n",
    "    # Generate random binary inputs (X) and expected outputs (y)\n",
    "    X = np.random.randint(0, 2, (N, N))  # N samples, N features\n",
    "    y = np.random.randint(0, 2, (N, 1))  # N samples, 1 output\n",
    "\n",
    "    # Randomly initialize weights and biases\n",
    "    np.random.seed()\n",
    "    w1 = np.random.uniform(-1, 1, (N, N))  # Input to hidden1\n",
    "    b1 = np.random.uniform(-1, 1, (1, N))\n",
    "    \n",
    "    w2 = np.random.uniform(-1, 1, (N, N))  # hidden1 to hidden2\n",
    "    b2 = np.random.uniform(-1, 1, (1, N))\n",
    "    \n",
    "    w3 = np.random.uniform(-1, 1, (N, 1))  # hidden2 to output\n",
    "    b3 = np.random.uniform(-1, 1, (1, 1))\n",
    "\n",
    "    steps = 0\n",
    "    for step in range(max_steps):\n",
    "        steps += 1\n",
    "        \n",
    "        # Forward Pass\n",
    "        z1 = np.dot(X, w1) + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(a1, w2) + b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, w3) + b3\n",
    "        output = sigmoid(z3)\n",
    "        \n",
    "        # Compute Error\n",
    "        error = y - output\n",
    "        if np.mean(np.abs(error)) < 0.01:  # Stop if error is small enough\n",
    "            break\n",
    "\n",
    "        # Backward Pass\n",
    "        d_output = error * sigmoid_derivative(output)\n",
    "        d_hidden2 = d_output.dot(w3.T) * sigmoid_derivative(a2)\n",
    "        d_hidden1 = d_hidden2.dot(w2.T) * sigmoid_derivative(a1)\n",
    "        \n",
    "        # Update Weights and Biases\n",
    "        w3 += a2.T.dot(d_output) * learning_rate\n",
    "        b3 += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "        w2 += a1.T.dot(d_hidden2) * learning_rate\n",
    "        b2 += np.sum(d_hidden2, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "        w1 += X.T.dot(d_hidden1) * learning_rate\n",
    "        b1 += np.sum(d_hidden1, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # Display final results\n",
    "    print(\"Final Weights and Biases after training:\\n\")\n",
    "    print(f\"w1 (Input -> Hidden Layer 1):\\n{w1}\\n\")\n",
    "    print(f\"b1 (Hidden Layer 1 bias):\\n{b1}\\n\")\n",
    "    \n",
    "    print(f\"w2 (Hidden Layer 1 -> Hidden Layer 2):\\n{w2}\\n\")\n",
    "    print(f\"b2 (Hidden Layer 2 bias):\\n{b2}\\n\")\n",
    "    \n",
    "    print(f\"w3 (Hidden Layer 2 -> Output):\\n{w3}\\n\")\n",
    "    print(f\"b3 (Output bias):\\n{b3}\\n\")\n",
    "    \n",
    "    print(f\"Total number of steps taken: {steps}\")\n",
    "\n",
    "# Example: Let's run with N=4 inputs\n",
    "simple_mlp(N=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470b30d-2b37-494a-bae4-9fefc8ed8b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd14a042-75d2-41e9-9a89-36ad3c89c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X:\n",
      " [[1 0 1 0]]\n",
      "\n",
      "Final hidden layer weights W1:\n",
      " [[-0.0410316   0.29180353  1.14193045 -1.48759998  0.1891206 ]\n",
      " [ 0.43944092  1.35224509  0.34405502  0.69464388  1.98709238]\n",
      " [-1.53436701  0.14317434  0.14585734  1.22938939 -1.50402059]\n",
      " [-0.3260788   0.8836129  -0.40147606  0.22181234 -2.2351063 ]]\n",
      "\n",
      "Final hidden layer bias b1:\n",
      " [ 1.65183974  1.26872176 -0.19194276 -0.56624191  1.41490578]\n",
      "\n",
      "Final output layer weights W2:\n",
      " [[ 0.2618235   1.24991765]\n",
      " [ 0.63790328  0.30834233]\n",
      " [ 0.49553841 -0.52469251]\n",
      " [-0.39931896 -0.20329315]\n",
      " [ 0.78615686  0.96542797]]\n",
      "\n",
      "Final output layer bias b2:\n",
      " [ 0.38007777 -0.93102578]\n",
      "\n",
      "Final output:\n",
      " [[1 1]]\n",
      "\n",
      "Total steps taken: 1\n"
     ]
    }
   ],
   "source": [
    "# 18) Implement a simple Multi-Layer Perceptron with 4 binary inputs, one\n",
    "# hidden layer and two binary outputs. Display the final weight matrices, bias\n",
    "# values and the number of steps. Note that random values are assigned to\n",
    "# weight matrices and bias in each step. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Step activation function\n",
    "def step_function(x):\n",
    "    return np.where(x >= 0, 1, 0)\n",
    "\n",
    "# Define MLP parameters\n",
    "input_size = 4\n",
    "hidden_size = 5   # You can choose any number for hidden neurons\n",
    "output_size = 2\n",
    "\n",
    "# Random weight initialization\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.random.randn(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.random.randn(output_size)\n",
    "\n",
    "# Dummy input data (4 binary inputs)\n",
    "X = np.random.randint(0, 2, (1, input_size))\n",
    "\n",
    "steps = 0\n",
    "output = None\n",
    "\n",
    "while True:\n",
    "    steps += 1\n",
    "\n",
    "    # Forward pass\n",
    "    hidden_input = np.dot(X, W1) + b1\n",
    "    hidden_output = step_function(hidden_input)\n",
    "\n",
    "    final_input = np.dot(hidden_output, W2) + b2\n",
    "    final_output = step_function(final_input)\n",
    "\n",
    "    # If final output is binary (0 or 1) for both outputs, break\n",
    "    if np.all((final_output == 0) | (final_output == 1)):\n",
    "        output = final_output\n",
    "        break\n",
    "    else:\n",
    "        # Randomize weights and biases again\n",
    "        W1 = np.random.randn(input_size, hidden_size)\n",
    "        b1 = np.random.randn(hidden_size)\n",
    "        W2 = np.random.randn(hidden_size, output_size)\n",
    "        b2 = np.random.randn(output_size)\n",
    "\n",
    "# Display results\n",
    "print(\"Input X:\\n\", X)\n",
    "print(\"\\nFinal hidden layer weights W1:\\n\", W1)\n",
    "print(\"\\nFinal hidden layer bias b1:\\n\", b1)\n",
    "print(\"\\nFinal output layer weights W2:\\n\", W2)\n",
    "print(\"\\nFinal output layer bias b2:\\n\", b2)\n",
    "print(\"\\nFinal output:\\n\", output)\n",
    "print(\"\\nTotal steps taken:\", steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab64c9-aff0-4a55-8469-c15b86292663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53f4c6f8-c8ae-4c90-8cf1-5160d9a53efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "\n",
      "Final Input X:\n",
      " [[1 1 1 0]\n",
      " [0 0 1 0]\n",
      " [0 1 1 0]\n",
      " [1 0 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 0 1]\n",
      " [0 0 0 0]\n",
      " [1 1 0 1]\n",
      " [0 1 0 1]\n",
      " [0 1 0 0]]\n",
      "\n",
      "Expected Output y:\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "Final Output after training:\n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "\n",
      "Final Weights and Biases:\n",
      "\n",
      "W1:\n",
      " [[-2.55445475 -2.15083361  0.99534847  0.38239427 -1.9960841 ]\n",
      " [-3.66727325  1.87589873  1.09897075  1.28305597 -1.11904212]\n",
      " [ 3.17326831  1.53481678 -1.90463115 -0.16661581  0.01695143]\n",
      " [-1.86780334  4.00943531  0.55108136  1.97956916  0.34763185]]\n",
      "\n",
      "b1:\n",
      " [-0.7117431  -2.04186313 -1.75185446  2.26582838  1.70981582]\n",
      "\n",
      "W2:\n",
      " [[-2.73195418  4.10781599  3.64133416]\n",
      " [-2.63910968  2.7175162   2.62260112]\n",
      " [-0.52558934  1.99141888  1.08521672]\n",
      " [ 1.87181805 -1.73757238 -0.90527455]\n",
      " [ 1.44405515 -1.91081543 -2.45711319]]\n",
      "\n",
      "b2:\n",
      " [-0.15360103 -0.66160177 -0.72712138]\n",
      "\n",
      "W3:\n",
      " [[ 4.39112425]\n",
      " [-5.69815166]\n",
      " [-4.53744416]]\n",
      "\n",
      "b3:\n",
      " [2.45245497]\n"
     ]
    }
   ],
   "source": [
    "# 19)Implement a simple Multi-Layer Perceptron with N binary inputs, two\n",
    "# hidden layers and one output. Use backpropagation and Sigmoid function\n",
    "# as activation function. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Define MLP structure\n",
    "N = 4  # Number of inputs (you can change N easily)\n",
    "hidden1_size = 5\n",
    "hidden2_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Random weight initialization\n",
    "W1 = np.random.randn(N, hidden1_size)\n",
    "b1 = np.random.randn(hidden1_size)\n",
    "\n",
    "W2 = np.random.randn(hidden1_size, hidden2_size)\n",
    "b2 = np.random.randn(hidden2_size)\n",
    "\n",
    "W3 = np.random.randn(hidden2_size, output_size)\n",
    "b3 = np.random.randn(output_size)\n",
    "\n",
    "# Dummy training data (binary inputs and binary output)\n",
    "X = np.random.randint(0, 2, (10, N))  # 10 samples\n",
    "y = np.random.randint(0, 2, (10, 1))\n",
    "\n",
    "# Training parameters\n",
    "epochs = 5000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training using Backpropagation\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    output = sigmoid(z3)\n",
    "\n",
    "    # Compute error\n",
    "    error = y - output\n",
    "\n",
    "    # Backward pass\n",
    "    d_output = error * sigmoid_derivative(output)\n",
    "    \n",
    "    d_hidden2 = np.dot(d_output, W3.T) * sigmoid_derivative(a2)\n",
    "    \n",
    "    d_hidden1 = np.dot(d_hidden2, W2.T) * sigmoid_derivative(a1)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W3 += learning_rate * np.dot(a2.T, d_output)\n",
    "    b3 += learning_rate * np.sum(d_output, axis=0)\n",
    "\n",
    "    W2 += learning_rate * np.dot(a1.T, d_hidden2)\n",
    "    b2 += learning_rate * np.sum(d_hidden2, axis=0)\n",
    "\n",
    "    W1 += learning_rate * np.dot(X.T, d_hidden1)\n",
    "    b1 += learning_rate * np.sum(d_hidden1, axis=0)\n",
    "\n",
    "# Final Results\n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"\\nFinal Input X:\\n\", X)\n",
    "print(\"\\nExpected Output y:\\n\", y)\n",
    "print(\"\\nFinal Output after training:\\n\", np.round(output))\n",
    "print(\"\\nFinal Weights and Biases:\")\n",
    "print(\"\\nW1:\\n\", W1)\n",
    "print(\"\\nb1:\\n\", b1)\n",
    "print(\"\\nW2:\\n\", W2)\n",
    "print(\"\\nb2:\\n\", b2)\n",
    "print(\"\\nW3:\\n\", W3)\n",
    "print(\"\\nb3:\\n\", b3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3bacbcb-962a-407c-b53f-b2e05e6d9ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X:\n",
      " [[1 1 1 0]\n",
      " [0 0 0 0]\n",
      " [0 1 1 1]\n",
      " [0 1 1 0]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 0 0 1]\n",
      " [1 1 1 1]\n",
      " [0 1 1 1]\n",
      " [0 0 0 1]]\n",
      "\n",
      "y:\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "Final Output:\n",
      " [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "\n",
      "W1:\n",
      " [[-0.78969374  0.13620941  2.12910416  1.48881481  2.80240248]\n",
      " [-0.68786214  2.84885921  1.85073692  2.45761665  1.03185645]\n",
      " [-1.01274347  1.35133146  0.8800574   1.65694021  0.84524494]\n",
      " [-0.40167145 -3.14312622  0.62551629  2.36554897  0.09125746]] \n",
      "b1:\n",
      " [-1.56258723  1.63072713  0.34775157 -0.85855873 -3.38811011]\n",
      "\n",
      "W2:\n",
      " [[ 0.7188879  -1.58386828 -0.23612709]\n",
      " [ 0.81308514 -1.25351891  3.86302288]\n",
      " [-0.18783689  1.42776731 -1.47281887]\n",
      " [-0.17088763  0.94086117 -3.7272438 ]\n",
      " [ 0.61762799 -2.20415967  3.35274977]] \n",
      "b2:\n",
      " [-0.59842465 -0.15545328  0.41385123]\n",
      "\n",
      "W3:\n",
      " [[-0.9891631 ]\n",
      " [ 2.77257352]\n",
      " [-7.3358372 ]] \n",
      "b3:\n",
      " [2.24467102]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid and its derivative\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "sigmoid_deriv = lambda x: x * (1 - x)\n",
    "\n",
    "# Structure\n",
    "N, h1, h2, out = 4, 5, 3, 1\n",
    "X = np.random.randint(0, 2, (10, N))\n",
    "y = np.random.randint(0, 2, (10, 1))\n",
    "\n",
    "# Random weights and biases\n",
    "W1, b1 = np.random.randn(N, h1), np.random.randn(h1)\n",
    "W2, b2 = np.random.randn(h1, h2), np.random.randn(h2)\n",
    "W3, b3 = np.random.randn(h2, out), np.random.randn(out)\n",
    "\n",
    "# Training\n",
    "for _ in range(5000):\n",
    "    a1 = sigmoid(X @ W1 + b1)\n",
    "    a2 = sigmoid(a1 @ W2 + b2)\n",
    "    out_pred = sigmoid(a2 @ W3 + b3)\n",
    "\n",
    "    error = y - out_pred\n",
    "    d_out = error * sigmoid_deriv(out_pred)\n",
    "    d_h2 = (d_out @ W3.T) * sigmoid_deriv(a2)\n",
    "    d_h1 = (d_h2 @ W2.T) * sigmoid_deriv(a1)\n",
    "\n",
    "    W3 += 0.1 * a2.T @ d_out; b3 += 0.1 * d_out.sum(0)\n",
    "    W2 += 0.1 * a1.T @ d_h2; b2 += 0.1 * d_h2.sum(0)\n",
    "    W1 += 0.1 * X.T @ d_h1; b1 += 0.1 * d_h1.sum(0)\n",
    "\n",
    "# Output\n",
    "print(\"\\nX:\\n\", X)\n",
    "print(\"\\ny:\\n\", y)\n",
    "print(\"\\nFinal Output:\\n\", np.round(out_pred))\n",
    "print(\"\\nW1:\\n\", W1, \"\\nb1:\\n\", b1)\n",
    "print(\"\\nW2:\\n\", W2, \"\\nb2:\\n\", b2)\n",
    "print(\"\\nW3:\\n\", W3, \"\\nb3:\\n\", b3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de810f4-f17e-4240-8304-8a09b8aef865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e4d0336-d14e-4768-8706-39c14fe52728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input X:\n",
      " [[1 1 0 1]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 1]\n",
      " [1 1 1 1]\n",
      " [0 1 1 0]\n",
      " [1 1 1 1]\n",
      " [0 1 1 1]\n",
      " [1 1 0 0]]\n",
      "\n",
      "Target y:\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "Predicted Output:\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "\n",
      "Weights and Biases:\n",
      "\n",
      "W1:\n",
      " [[ 0.88474576  1.36808328  0.07144241  0.09324905 -1.04656037]\n",
      " [-0.05796008  0.88661389 -0.67030724 -0.17550487  1.41639372]\n",
      " [ 0.16049604  0.13922503  1.39758542 -0.20317397  0.01977739]\n",
      " [-0.40342004 -1.28988348 -0.79792231 -2.11886028  0.89666267]] \n",
      "b1:\n",
      " [-0.75776261  0.51172474 -0.44880151  1.09706334 -1.41519948]\n",
      "\n",
      "W2:\n",
      " [[ 0.53608899 -0.06319375 -0.5233127 ]\n",
      " [ 0.63628524 -0.13744583 -0.05202903]\n",
      " [-0.51082596 -1.60780251 -0.32007661]\n",
      " [-0.1873157   0.2195473  -0.70032094]\n",
      " [-0.67172052  0.63927926  0.48708493]] \n",
      "b2:\n",
      " [ 1.46007953 -0.22123902  0.12010799]\n",
      "\n",
      "W3:\n",
      " [[-0.92003952]\n",
      " [ 0.73196718]\n",
      " [ 1.34290339]] \n",
      "b3:\n",
      " [0.93446596]\n"
     ]
    }
   ],
   "source": [
    "# 20)Implement a simple Multi-Layer Perceptron with N binary inputs, two\n",
    "# hidden layers and one output. Use backpropagation and ReLU function as\n",
    "# activation function. \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ReLU and its derivative\n",
    "relu = lambda x: np.maximum(0, x)\n",
    "relu_deriv = lambda x: (x > 0).astype(float)\n",
    "\n",
    "# Setup\n",
    "N, h1, h2, out = 4, 5, 3, 1\n",
    "X = np.random.randint(0, 2, (10, N))\n",
    "y = np.random.randint(0, 2, (10, 1))\n",
    "\n",
    "# Random weights and biases\n",
    "W1, b1 = np.random.randn(N, h1), np.random.randn(h1)\n",
    "W2, b2 = np.random.randn(h1, h2), np.random.randn(h2)\n",
    "W3, b3 = np.random.randn(h2, out), np.random.randn(out)\n",
    "\n",
    "# Training\n",
    "for _ in range(5000):\n",
    "    a1 = relu(X @ W1 + b1)\n",
    "    a2 = relu(a1 @ W2 + b2)\n",
    "    out_pred = relu(a2 @ W3 + b3)\n",
    "\n",
    "    error = y - out_pred\n",
    "    d_out = error * relu_deriv(out_pred)\n",
    "    d_h2 = (d_out @ W3.T) * relu_deriv(a2)\n",
    "    d_h1 = (d_h2 @ W2.T) * relu_deriv(a1)\n",
    "\n",
    "    W3 += 0.01 * a2.T @ d_out; b3 += 0.01 * d_out.sum(0)\n",
    "    W2 += 0.01 * a1.T @ d_h2; b2 += 0.01 * d_h2.sum(0)\n",
    "    W1 += 0.01 * X.T @ d_h1; b1 += 0.01 * d_h1.sum(0)\n",
    "\n",
    "# Output\n",
    "print(\"\\nInput X:\\n\", X)\n",
    "print(\"\\nTarget y:\\n\", y)\n",
    "print(\"\\nPredicted Output:\\n\", np.round(out_pred))\n",
    "print(\"\\nWeights and Biases:\")\n",
    "print(\"\\nW1:\\n\", W1, \"\\nb1:\\n\", b1)\n",
    "print(\"\\nW2:\\n\", W2, \"\\nb2:\\n\", b2)\n",
    "print(\"\\nW3:\\n\", W3, \"\\nb3:\\n\", b3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c987cb-beea-4fe4-952a-b746a5ec7ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0fa1624-905d-451d-a1f4-8efe631b85b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input X:\n",
      " [[0 1 1 1]\n",
      " [0 0 1 1]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 1 1]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]\n",
      " [0 0 1 0]\n",
      " [1 0 1 0]\n",
      " [0 1 0 0]]\n",
      "\n",
      "Target y:\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Predicted Output:\n",
      " [[-0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "\n",
      "Weights and Biases:\n",
      "\n",
      "W1:\n",
      " [[ 0.68075238  1.03968008  1.41703038  0.89401232  0.49727056]\n",
      " [-2.04624181 -1.23267467  1.4842481  -0.41272216 -0.49164396]\n",
      " [-0.8665011  -1.43201912 -0.2138146  -0.52050544 -1.80060796]\n",
      " [ 0.7659396   1.00754259  1.56239886 -0.17961439 -1.45828695]] \n",
      "b1:\n",
      " [ 1.36331068 -0.31408979 -0.53297239 -1.4109589   0.00437003]\n",
      "\n",
      "W2:\n",
      " [[ 1.97673958  1.07972611  0.63209803]\n",
      " [-0.84409575 -0.77725052 -1.92427574]\n",
      " [ 0.81459789  0.71755601  1.18583205]\n",
      " [ 0.16916452  1.33117213  0.37619344]\n",
      " [ 0.15902661  0.43143186  0.62573819]] \n",
      "b2:\n",
      " [ 0.92794325  2.00300852 -0.88140559]\n",
      "\n",
      "W3:\n",
      " [[-0.6451436 ]\n",
      " [ 0.4680761 ]\n",
      " [-2.67652401]] \n",
      "b3:\n",
      " [1.76265396]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tanh and its derivative\n",
    "tanh = lambda x: np.tanh(x)\n",
    "tanh_deriv = lambda x: 1 - np.tanh(x)**2\n",
    "\n",
    "# Setup\n",
    "N, h1, h2, out = 4, 5, 3, 1\n",
    "X = np.random.randint(0, 2, (10, N))\n",
    "y = np.random.randint(0, 2, (10, 1))\n",
    "\n",
    "# Random weights and biases\n",
    "W1, b1 = np.random.randn(N, h1), np.random.randn(h1)\n",
    "W2, b2 = np.random.randn(h1, h2), np.random.randn(h2)\n",
    "W3, b3 = np.random.randn(h2, out), np.random.randn(out)\n",
    "\n",
    "# Training\n",
    "for _ in range(5000):\n",
    "    a1 = tanh(X @ W1 + b1)\n",
    "    a2 = tanh(a1 @ W2 + b2)\n",
    "    out_pred = tanh(a2 @ W3 + b3)\n",
    "\n",
    "    error = y - out_pred\n",
    "    d_out = error * tanh_deriv(out_pred)\n",
    "    d_h2 = (d_out @ W3.T) * tanh_deriv(a2)\n",
    "    d_h1 = (d_h2 @ W2.T) * tanh_deriv(a1)\n",
    "\n",
    "    W3 += 0.01 * a2.T @ d_out; b3 += 0.01 * d_out.sum(0)\n",
    "    W2 += 0.01 * a1.T @ d_h2; b2 += 0.01 * d_h2.sum(0)\n",
    "    W1 += 0.01 * X.T @ d_h1; b1 += 0.01 * d_h1.sum(0)\n",
    "\n",
    "# Output\n",
    "print(\"\\nInput X:\\n\", X)\n",
    "print(\"\\nTarget y:\\n\", y)\n",
    "print(\"\\nPredicted Output:\\n\", np.round(out_pred))\n",
    "print(\"\\nWeights and Biases:\")\n",
    "print(\"\\nW1:\\n\", W1, \"\\nb1:\\n\", b1)\n",
    "print(\"\\nW2:\\n\", W2, \"\\nb2:\\n\", b2)\n",
    "print(\"\\nW3:\\n\", W3, \"\\nb3:\\n\", b3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea96f54-d742-4fef-bb5e-6b3ba96e8b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9e128fd-ba71-4428-aea2-809ae735193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 624.3/624.3 kB 3.3 MB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install re\n",
    "!pip install nltk\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71f4781-aeda-4dcd-a7f4-74694ca11b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vraj\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Vraj\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f4b7f2-aa07-42b5-8789-e19b0c7efe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Vraj\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned and Corrected Text:\n",
      "\n",
      "sun rises east birds chip morning flowers bloom fresh colors children play parts books hold key wisdom music soothe soul rain nourished earth trees sway gentle breeze rivers flow endless seas mountains stand tall proud stars shine brightly night moon grows soft light people walk dogs evening artists paint beautiful landscape writers imagine fantastic worlds teachers educate future generations farmers cultivate crops care scientists explore universe doctors heal sick engineers build amazing structures athletes push limits win poets express emotions words leaders inspire change friends share laughter sorrows families celebrate festival together dreams fuel ambitions challenges teach residence opportunities knock quietly courage opens new doors hope lights darkness paths kindness spreads warmth gratitude strengthens bonds learning never ends travel broaden horizons reading enriches minds conversations create connections silence brings peace patience bears fruit smiles bridge differences every sunrise brings new beginnings every sunset promises rest life journey embrace every step\n"
     ]
    }
   ],
   "source": [
    "# 22)Write a program to read a text file with at least 30 sentences and 200 words\n",
    "# and perform the following tasks in the given sequence.\n",
    "# a. Text cleaning by removing punctuation/special characters, numbers\n",
    "# and extra white spaces. Use regular expression for the same.\n",
    "# b. Convert text to lowercase\n",
    "# c. Tokenization\n",
    "# d. Remove stop words\n",
    "# e. Correct misspelled words \n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "file_path = r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\The sun rises in the east. Birds ch.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Cleaning\n",
    "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "text = re.sub(r'\\s+', ' ', text)\n",
    "text = text.lower()\n",
    "\n",
    "# Tokenization (simple way)\n",
    "tokens = text.split()\n",
    "\n",
    "# Remove Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Correct Spelling\n",
    "corrected_tokens = [str(TextBlob(word).correct()) for word in filtered_tokens]\n",
    "\n",
    "# Final output\n",
    "print(\"\\nCleaned and Corrected Text:\\n\")\n",
    "print(' '.join(corrected_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179be556-0f5c-43e6-9eae-1bc451ef53a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062201d8-2ca6-44ad-aa0b-485eee3e8ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized Tokens:\n",
      " ['the', 'sun', 'rise', 'in', 'the', 'east', 'bird', 'chirp', 'in', 'the', 'morn', 'flower', 'bloom', 'with', 'fresh', 'color', 'child', 'play', 'in', 'the', 'park', 'book', 'hold', 'the', 'key', 'to', 'wisdom', 'music', 'sooth', 'the', 'soul', 'rain', 'nourish', 'the', 'earth', 'tree', 'sway', 'in', 'the', 'gentl', 'breez', 'river', 'flow', 'endlessli', 'to', 'the', 'sea', 'mountain', 'stand', 'tall', 'and', 'proud', 'star', 'shine', 'brightli', 'at', 'night', 'the', 'moon', 'glow', 'with', 'soft', 'light', 'peopl', 'walk', 'their', 'dog', 'in', 'the', 'even', 'artist', 'paint', 'beauti', 'landscap', 'writer', 'imagin', 'fantast', 'world', 'teacher', 'educ', 'futur', 'gener', 'farmer', 'cultiv', 'crop', 'with', 'care', 'scientist', 'explor', 'the', 'univers', 'doctor', 'heal', 'the', 'sick', 'engin', 'build', 'amaz', 'structur', 'athlet', 'push', 'their', 'limit', 'to', 'win', 'poet', 'express', 'emot', 'in', 'word', 'leader', 'inspir', 'chang', 'friend', 'share', 'laughter', 'and', 'sorrow', 'famili', 'celebr', 'festiv', 'togeth', 'dream', 'fuel', 'ambit', 'challeng', 'teach', 'resili', 'opportun', 'knock', 'quietli', 'courag', 'open', 'new', 'door', 'hope', 'light', 'the', 'darkest', 'path', 'kind', 'spread', 'warmth', 'gratitud', 'strengthen', 'bond', 'learn', 'never', 'end', 'travel', 'broaden', 'horizon', 'read', 'enrich', 'mind', 'convers', 'creat', 'connect', 'silenc', 'bring', 'peac', 'patienc', 'bear', 'fruit', 'smile', 'bridg', 'differ', 'everi', 'sunris', 'bring', 'new', 'begin', 'everi', 'sunset', 'promis', 'rest', 'life', 'is', 'a', 'journey', 'embrac', 'everi', 'step']\n",
      "\n",
      "List of 3-Consecutive Words:\n",
      " ['the sun rise', 'sun rise in', 'rise in the', 'in the east', 'the east bird', 'east bird chirp', 'bird chirp in', 'chirp in the', 'in the morn', 'the morn flower', 'morn flower bloom', 'flower bloom with', 'bloom with fresh', 'with fresh color', 'fresh color child', 'color child play', 'child play in', 'play in the', 'in the park', 'the park book', 'park book hold', 'book hold the', 'hold the key', 'the key to', 'key to wisdom', 'to wisdom music', 'wisdom music sooth', 'music sooth the', 'sooth the soul', 'the soul rain', 'soul rain nourish', 'rain nourish the', 'nourish the earth', 'the earth tree', 'earth tree sway', 'tree sway in', 'sway in the', 'in the gentl', 'the gentl breez', 'gentl breez river', 'breez river flow', 'river flow endlessli', 'flow endlessli to', 'endlessli to the', 'to the sea', 'the sea mountain', 'sea mountain stand', 'mountain stand tall', 'stand tall and', 'tall and proud', 'and proud star', 'proud star shine', 'star shine brightli', 'shine brightli at', 'brightli at night', 'at night the', 'night the moon', 'the moon glow', 'moon glow with', 'glow with soft', 'with soft light', 'soft light peopl', 'light peopl walk', 'peopl walk their', 'walk their dog', 'their dog in', 'dog in the', 'in the even', 'the even artist', 'even artist paint', 'artist paint beauti', 'paint beauti landscap', 'beauti landscap writer', 'landscap writer imagin', 'writer imagin fantast', 'imagin fantast world', 'fantast world teacher', 'world teacher educ', 'teacher educ futur', 'educ futur gener', 'futur gener farmer', 'gener farmer cultiv', 'farmer cultiv crop', 'cultiv crop with', 'crop with care', 'with care scientist', 'care scientist explor', 'scientist explor the', 'explor the univers', 'the univers doctor', 'univers doctor heal', 'doctor heal the', 'heal the sick', 'the sick engin', 'sick engin build', 'engin build amaz', 'build amaz structur', 'amaz structur athlet', 'structur athlet push', 'athlet push their', 'push their limit', 'their limit to', 'limit to win', 'to win poet', 'win poet express', 'poet express emot', 'express emot in', 'emot in word', 'in word leader', 'word leader inspir', 'leader inspir chang', 'inspir chang friend', 'chang friend share', 'friend share laughter', 'share laughter and', 'laughter and sorrow', 'and sorrow famili', 'sorrow famili celebr', 'famili celebr festiv', 'celebr festiv togeth', 'festiv togeth dream', 'togeth dream fuel', 'dream fuel ambit', 'fuel ambit challeng', 'ambit challeng teach', 'challeng teach resili', 'teach resili opportun', 'resili opportun knock', 'opportun knock quietli', 'knock quietli courag', 'quietli courag open', 'courag open new', 'open new door', 'new door hope', 'door hope light', 'hope light the', 'light the darkest', 'the darkest path', 'darkest path kind', 'path kind spread', 'kind spread warmth', 'spread warmth gratitud', 'warmth gratitud strengthen', 'gratitud strengthen bond', 'strengthen bond learn', 'bond learn never', 'learn never end', 'never end travel', 'end travel broaden', 'travel broaden horizon', 'broaden horizon read', 'horizon read enrich', 'read enrich mind', 'enrich mind convers', 'mind convers creat', 'convers creat connect', 'creat connect silenc', 'connect silenc bring', 'silenc bring peac', 'bring peac patienc', 'peac patienc bear', 'patienc bear fruit', 'bear fruit smile', 'fruit smile bridg', 'smile bridg differ', 'bridg differ everi', 'differ everi sunris', 'everi sunris bring', 'sunris bring new', 'bring new begin', 'new begin everi', 'begin everi sunset', 'everi sunset promis', 'sunset promis rest', 'promis rest life', 'rest life is', 'life is a', 'is a journey', 'a journey embrac', 'journey embrac everi', 'embrac everi step']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Vraj\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Vraj\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 23) Write a program to read a text file with at least 30 sentences and 200 words\n",
    "# and perform the following tasks in the given sequence.\n",
    "# a. Text cleaning by removing punctuation/special characters, numbers\n",
    "# and extra white spaces. Use regular expression for the same.\n",
    "# b. Convert text to lowercase\n",
    "# c. Stemming and Lemmatization\n",
    "# d. Create a list of 3 consecutive words after lemmatization \n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Step 1: Read File\n",
    "file_path = r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\The sun rises in the east. Birds ch.txt\" # <<< Change accordingly\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Step 2: Text Cleaning\n",
    "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "# Step 3: Lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Step 4: Tokenization (Simple Split)\n",
    "tokens = text.split()\n",
    "\n",
    "# Step 5: Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "# Step 6: Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
    "\n",
    "# Step 7: 3-Consecutive Words (triplets)\n",
    "triplets = [' '.join(lemmatized_tokens[i:i+3]) for i in range(len(lemmatized_tokens)-2)]\n",
    "\n",
    "# Final Outputs\n",
    "print(\"\\nLemmatized Tokens:\\n\", lemmatized_tokens)\n",
    "print(\"\\nList of 3-Consecutive Words:\\n\", triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd68a8-8ec9-4749-9378-931d42f1a7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4f6621-0268-4a53-b485-590cb654a34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 394\n",
      "Vocabulary List:\n",
      " ['a', 'abbreviated', 'about', 'access', 'across', 'advancements', 'agents', 'agreement', 'ai', 'aidriven', 'aim', 'alexa', 'algorithms', 'allows', 'also', 'although', 'amazon', 'amount', 'an', 'analytics', 'analyze', 'and', 'another', 'applications', 'are', 'artificial', 'as', 'assets', 'assist', 'assistants', 'assure', 'attacks', 'authority', 'automatically', 'autonomous', 'autonomously', 'avoid', 'azure', 'backbone', 'bank', 'based', 'basis', 'behind', 'being', 'bias', 'big', 'bitcoin', 'block', 'blockchain', 'blockchains', 'blocks', 'branch', 'brings', 'build', 'businesses', 'by', 'can', 'capabilities', 'carefully', 'centers', 'central', 'certifications', 'chain', 'chains', 'challenge', 'change', 'changes', 'climate', 'closer', 'cloud', 'cloudnative', 'clouds', 'code', 'coded', 'collaboration', 'combine', 'companies', 'complex', 'compliance', 'composed', 'computation', 'computer', 'computing', 'concepts', 'concern', 'concerns', 'consensus', 'containing', 'contract', 'contracts', 'contributing', 'controls', 'costefficiency', 'costs', 'create', 'creating', 'crucial', 'cryptocurrency', 'cryptographic', 'currencies', 'customers', 'data', 'databases', 'decentralization', 'decisionmaking', 'decisions', 'deep', 'delivers', 'delivery', 'demand', 'deploy', 'deployment', 'designed', 'detection', 'developers', 'developing', 'development', 'developments', 'diagnosis', 'digital', 'diseases', 'disruption', 'distributed', 'down', 'dropbox', 'each', 'economy', 'edge', 'education', 'eliminates', 'employment', 'enabled', 'enables', 'encryption', 'enforce', 'ensure', 'ensures', 'environment', 'environments', 'essential', 'ethereum', 'ethical', 'even', 'everyday', 'everyone', 'evolving', 'examples', 'exclusive', 'experiences', 'explainable', 'explicitly', 'exploring', 'finance', 'flexibility', 'for', 'framework', 'fraud', 'from', 'future', 'global', 'gmail', 'governments', 'has', 'hash', 'have', 'healthcare', 'heavily', 'held', 'human', 'hybrid', 'iaas', 'identity', 'impacting', 'improve', 'improves', 'in', 'include', 'industries', 'infrastructure', 'initially', 'innovations', 'input', 'integrates', 'integration', 'integrity', 'intelligence', 'interact', 'interacting', 'internet', 'interpret', 'investing', 'iot', 'is', 'it', 'its', 'key', 'language', 'latency', 'layer', 'layers', 'learn', 'learning', 'led', 'ledger', 'lightning', 'like', 'lives', 'looks', 'machine', 'machines', 'main', 'maintaining', 'major', 'make', 'management', 'managing', 'mechanisms', 'medical', 'microsoft', 'migration', 'mimic', 'models', 'more', 'multicloud', 'multiple', 'must', 'natural', 'need', 'network', 'networking', 'networks', 'neural', 'nfts', 'nonfungible', 'not', 'occur', 'of', 'offer', 'offers', 'often', 'on', 'only', 'onto', 'open', 'operated', 'or', 'organization', 'organizations', 'our', 'over', 'owning', 'paas', 'participants', 'participating', 'patterns', 'perform', 'personalizes', 'physical', 'pitfalls', 'plan', 'platform', 'policies', 'popular', 'potential', 'practical', 'practices', 'predict', 'previous', 'privacy', 'private', 'processes', 'processing', 'programmed', 'promises', 'promising', 'proof', 'proofs', 'protecting', 'providers', 'provides', 'public', 'puzzles', 'quantum', 'rapidly', 'reasoning', 'record', 'reduce', 'reducing', 'refers', 'regulate', 'reinforcement', 'remain', 'remains', 'remote', 'removing', 'representative', 'requires', 'research', 'researchers', 'resources', 'responsibly', 'restrict', 'revolutionizing', 'risk', 'robotics', 'saas', 'scalability', 'scale', 'secure', 'secured', 'security', 'selected', 'selects', 'selfexecuting', 'series', 'serverless', 'servers', 'service', 'services', 'sharing', 'simulation', 'single', 'siri', 'smart', 'software', 'solutions', 'solving', 'source', 'specifically', 'speed', 'stake', 'storage', 'structure', 'students', 'subscription', 'subset', 'supply', 'support', 'supports', 'systems', 'tamperproof', 'tasks', 'technology', 'terms', 'that', 'the', 'their', 'there', 'these', 'they', 'thirdparty', 'this', 'three', 'timestamp', 'to', 'tokens', 'top', 'traceability', 'training', 'transaction', 'transactions', 'transformative', 'transforming', 'transparency', 'transparent', 'trend', 'type', 'underlying', 'understand', 'understanding', 'up', 'used', 'uses', 'using', 'validators', 'vehicles', 'verifiable', 'virtualization', 'virtualized', 'vision', 'visual', 'voice', 'voting', 'was', 'web', 'when', 'where', 'while', 'with', 'without', 'work', 'worrying', 'write', 'zeroknowledge']\n",
      "\n",
      "One-Hot Encoding for File 1:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "One-Hot Encoding for File 2:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "One-Hot Encoding for File 3:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 24) Write a program to read a 3 text files on any technical concept with at least\n",
    "# 20 sentences and 150 words. Implement one-hot encoding. \n",
    "\n",
    "import re\n",
    "\n",
    "# Function to read and clean text\n",
    "def read_and_clean(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Function to create vocabulary\n",
    "def build_vocab(texts):\n",
    "    vocab = set()\n",
    "    for text in texts:\n",
    "        vocab.update(text.split())\n",
    "    vocab = sorted(list(vocab))  # Sort for consistent order\n",
    "    return vocab\n",
    "\n",
    "# Function to one-hot encode a text\n",
    "def one_hot_encode(text, vocab):\n",
    "    words = text.split()\n",
    "    word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "    one_hot_vectors = []\n",
    "    for word in words:\n",
    "        vector = [0] * len(vocab)\n",
    "        if word in word_to_index:\n",
    "            vector[word_to_index[word]] = 1\n",
    "        one_hot_vectors.append(vector)\n",
    "    return one_hot_vectors\n",
    "\n",
    "# Step 1: Read and Clean the 3 files\n",
    "file1 = r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 24 - Artificial Intelligence, often abbr.txt\" # Change this\n",
    "file2 = r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 24 - Blockchain is a distributed ledger.txt\" # Change this\n",
    "file3 = r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 24 - Cloud computing is the delivery of.txt\"  # Change this\n",
    "\n",
    "text1 = read_and_clean(file1)\n",
    "text2 = read_and_clean(file2)\n",
    "text3 = read_and_clean(file3)\n",
    "\n",
    "texts = [text1, text2, text3]\n",
    "\n",
    "# Step 2: Build vocabulary from all files\n",
    "vocab = build_vocab(texts)\n",
    "print(\"Vocabulary Size:\", len(vocab))\n",
    "print(\"Vocabulary List:\\n\", vocab)\n",
    "\n",
    "# Step 3: One-Hot Encode each text\n",
    "encoded_texts = [one_hot_encode(text, vocab) for text in texts]\n",
    "\n",
    "# Step 4: Display results\n",
    "for i, encoded in enumerate(encoded_texts, start=1):\n",
    "    print(f\"\\nOne-Hot Encoding for File {i}:\")\n",
    "    for vector in encoded[:10]:  # Show only first 10 vectors for readability\n",
    "        print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2e273-b736-4227-bfbe-126eb2b66c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f2c6267-438b-4328-a9aa-8b7701d5edf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vraj shah\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "Vocabulary (Words extracted):\n",
      "['21st' 'achievement' 'achievements' 'act' 'action' 'adds' 'again'\n",
      " 'against' 'also' 'ambitious' 'an' 'and' 'anne' 'are' 'arguably' 'as'\n",
      " 'astonishing' 'attention' 'audience' 'audiences' 'avoiding' 'awe'\n",
      " 'balances' 'bale' 'batman' 'be' 'beautifully' 'between' 'black' 'blends'\n",
      " 'blurs' 'bond' 'book' 'both' 'breathtaking' 'brilliance' 'brilliantly'\n",
      " 'brings' 'builds' 'but' 'by' 'captures' 'careful' 'case' 'cast' 'century'\n",
      " 'cgi' 'challenges' 'chaos' 'character' 'characters' 'chastain' 'chilling'\n",
      " 'choice' 'christian' 'christopher' 'cinema' 'cinematography' 'city'\n",
      " 'classic' 'cobb' 'comic' 'compelling' 'complements' 'complex' 'concept'\n",
      " 'conflicted' 'confront' 'cooper' 'core' 'could' 'crafted' 'credibility'\n",
      " 'crime' 'critics' 'dark' 'daughter' 'debating' 'deliver' 'delivers'\n",
      " 'demands' 'dent' 'depiction' 'depth' 'detail' 'dicaprio' 'dilation'\n",
      " 'dimension' 'directed' 'direction' 'divisive' 'drama' 'dream' 'dreaming'\n",
      " 'dreams' 'duality' 'dying' 'each' 'earth' 'eerily' 'effects' 'elevates'\n",
      " 'ellen' 'emotional' 'ending' 'ends' 'ensemble' 'entertains' 'epic' 'ever'\n",
      " 'every' 'excess' 'executed' 'explores' 'extractor' 'face' 'falters'\n",
      " 'father' 'feels' 'fi' 'fiction' 'fight' 'film' 'filmmaking' 'films'\n",
      " 'final' 'for' 'forces' 'found' 'from' 'full' 'gives' 'gordon' 'gotham'\n",
      " 'grand' 'grandeur' 'gravity' 'greatest' 'groundbreaking' 'grounded'\n",
      " 'guilt' 'hallway' 'handled' 'hans' 'harvey' 'has' 'hathaway' 'haunting'\n",
      " 'heart' 'heartfelt' 'heath' 'hero' 'hidden' 'himself' 'his' 'holes'\n",
      " 'however' 'human' 'humor' 'iconic' 'imax' 'impact' 'impossible' 'in'\n",
      " 'inception' 'including' 'influential' 'input' 'inspiring' 'intellectual'\n",
      " 'intense' 'interrogation' 'interstellar' 'into' 'intricate' 'is' 'it'\n",
      " 'its' 'jessica' 'joker' 'joseph' 'kip' 'knight' 'layer' 'leaves'\n",
      " 'leaving' 'ledger' 'leonardo' 'level' 'levitt' 'like' 'line' 'loose'\n",
      " 'love' 'made' 'master' 'masterpiece' 'matthew' 'mcconaughey' 'meanings'\n",
      " 'memorable' 'meticulous' 'modern' 'monumental' 'morality' 'most'\n",
      " 'motivation' 'movie' 'movies' 'much' 'music' 'narrative' 'never' 'new'\n",
      " 'no' 'nolan' 'nothing' 'odds' 'of' 'once' 'one' 'overwhelming' 'pacing'\n",
      " 'page' 'particularly' 'patience' 'performance' 'performances' 'physicist'\n",
      " 'plagued' 'planet' 'plot' 'portrayal' 'powerful' 'practical' 'problems'\n",
      " 'proves' 'provide' 'questions' 'real' 'realism' 'realistic' 'redefined'\n",
      " 'relentless' 'remains' 'reprises' 'resilience' 'revolutionary' 'rewards'\n",
      " 'rewatch' 'robot' 'role' 'roles' 'scale' 'scene' 'scenes' 'sci' 'science'\n",
      " 'scientific' 'score' 'script' 'seamlessly' 'seek' 'sense' 'sequences'\n",
      " 'set' 'shared' 'shine' 'shoot' 'short' 'show' 'some' 'space'\n",
      " 'spectacular' 'standard' 'steals' 'stellar' 'stimulation' 'story'\n",
      " 'storyteller' 'storytelling' 'stunning' 'successfully' 'superhero'\n",
      " 'surrounding' 'survival' 'tackles' 'tars' 'technical' 'tension' 'that'\n",
      " 'the' 'their' 'themes' 'theory' 'thorne' 'thriller' 'throughout' 'tight'\n",
      " 'time' 'timeless' 'to' 'tone' 'tragic' 'transformation' 'travel' 'two'\n",
      " 'uncomfortable' 'uncovers' 'undoubtedly' 'unforgettable' 'unsurpassed'\n",
      " 'viewers' 'villain' 'visual' 'visually' 'visuals' 'what' 'who' 'with'\n",
      " 'within' 'world' 'wormholes' 'zero' 'zimmer']\n",
      "\n",
      "Bag of Words Matrix (Word Counts):\n",
      "[[ 0  0  0  0  2  1  0  0  0  0  0  7  0  1  1  3  0  0  1  0  1  0  0  1\n",
      "   2  0  1  2  0  0  1  0  1  1  0  0  0  1  1  0  1  1  0  0  0  0  1  0\n",
      "   1  1  0  0  1  1  1  1  1  1  2  0  0  1  1  0  1  0  1  1  0  0  0  0\n",
      "   0  1  0  4  0  0  0  0  0  1  0  1  0  0  0  0  0  1  0  0  0  0  0  1\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  0  1  0  1  1  0  1  0\n",
      "   0  0  2  0  0  0  1  1  0  0  0  0  0  2  0  1  0  1  0  0  0  0  0  1\n",
      "   1  1  0  0  0  0  1  1  0  0  1  0  1  0  0  1  1  0  0  1  0  0  0  0\n",
      "   0  0  1  1  0  1  0  9  3  0  0  2  0  0  3  0  0  0  2  0  0  0  2  1\n",
      "   0  0  1  0  1  0  0  0  0  0  1  0  1  0  1  3  1  1  0  0  1  1  0  2\n",
      "   0  0  2  0  0  0  1  0  0  0  1  0  0  1  0  0  0  0  1  1  0  0  1  2\n",
      "   1  0  0  0  1  1  0  0  0  0  0  1  0  0  1  1  0  0  0  1  1  0  0  1\n",
      "   1  1  0  0  1  0  1  0  0  0  1  1  0  0  1  0  0  0  0  2  0  0  0  0\n",
      "   0  1  2 18  0  1  0  0  1  1  1  0  0  3  1  1  1  0  1  1  0  0  1  1\n",
      "   0  1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  1  1  1  0  1  1  1  1  1  1 10  1  3  0  3  0  1  0  0  0  1  0  0\n",
      "   0  0  0  1  1  1  0  1  0  0  0  1  0  0  0  1  1  0  1  1  0  0  0  0\n",
      "   0  0  1  1  0  0  0  1  0  0  0  0  0  0  0  1  1  0  0  0  1  1  0  0\n",
      "   1  0  1  0  1  0  0  1  1  0  1  1  0  0  1  0  1  0  1  0  0  0  0  0\n",
      "   1  0  1  1  0  0  0  4  1  0  0  0  1  0  0  0  0  1  0  0  0  1  1  0\n",
      "   2  0  2  1  0  1  0  0  1  0  0  0  0  0  1  0  0  0  1  1  0  0  1  1\n",
      "   0  0  1  1  1  0  0  0  0  1  1  1  0  2  1  0  0  1  1  3  0  0  0  1\n",
      "   1  1  0  0  3  0  0  5  1  1  1  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  1  0  1  0  1  1  0  0  0  0  1  0  0  0  2  0  0  0  1  0  0  0  3\n",
      "   1  1  6  1  0  0  0  0  0  1  1  0  1  0  1  0  1  1  0  0  1  1  0  0\n",
      "   0  1  0  0  0  0  1  0  1  0  1  0  1  1  0  1  0  3  1  1  0  0  1  0\n",
      "   0  0  0  1  0  1  0  1  1  0  0  0  0  1  1  1  1  1  1  0  0  1  1  1\n",
      "   1  0  0 14  1  1  1  1  0  0  0  2  0  1  0  0  0  1  0  0  0  1  0  0\n",
      "   1  0  0  1  1  0  1  2  0  0  1  0  1]\n",
      " [ 1  0  0  0  1  1  0  0  0  0  0  5  0  1  0  1  1  2  1  1  0  0  1  0\n",
      "   0  1  0  0  0  0  0  0  0  0  1  0  1  0  0  1  1  0  0  0  1  1  0  1\n",
      "   0  0  0  0  0  0  0  1  0  1  0  1  2  0  0  0  1  1  0  0  0  0  1  1\n",
      "   0  0  0  0  0  1  1  0  1  0  0  1  1  1  0  1  0  1  0  1  2  1  2  0\n",
      "   0  1  0  0  1  1  1  1  1  1  1  1  0  0  2  0  1  1  1  0  0  0  0  1\n",
      "   1  1  0  0  1  1  0  0  0  1  1  1  1  0  0  0  1  0  0  0  1  1  0  1\n",
      "   0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  3  1  1  0\n",
      "   0  0  0  0  0  0  1  9  1  0  0  0  1  0  0  1  1  1  0  1  1  1  0  0\n",
      "   1  0  0  0  1  0  0  1  1  1  0  0  0  1  0  3  0  0  1  0  1  3  1  2\n",
      "   0  0  4  0  1  1  1  1  1  0  1  1  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0  1  1  1  0  0  1  0  1  0  0  0  0  2  0  1  1  0  1  0  1  0  0\n",
      "   0  0  1  0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0  0  1  0  0  0\n",
      "   0  0  1 18  0  0  0  0  1  0  0  0  1  3  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  1  0  0  1  0  0  1  1  0  1  1]]\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "\n",
    "# Step 1: Read the contents of the 3 movie review files\n",
    "file_names = [\n",
    "    r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 25 - The Dark Knight iReview.txt\",\n",
    "    r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\exp 25 - Interstellar review.txt\",\n",
    "    r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 25 - Inception Review.txt\"\n",
    "]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        documents.append(file.read())\n",
    "\n",
    "# Step 2: Initialize CountVectorizer (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Step 3: Fit and Transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 4: Display the vocabulary\n",
    "print(\"\\nVocabulary (Words extracted):\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Step 5: Display the Bag of Words Matrix\n",
    "print(\"\\nBag of Words Matrix (Word Counts):\")\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ec40c-da55-4768-9a75-4ba9f031ead4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b33c34-da51-4c94-853b-debb74205a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF for C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 26 - The Eiffel Tower.txt:\n",
      "the: 0.0663\n",
      "it: 0.0612\n",
      "tower: 0.0518\n",
      "and: 0.0306\n",
      "of: 0.0306\n",
      "to: 0.0306\n",
      "eiffel: 0.0263\n",
      "is: 0.0255\n",
      "was: 0.0204\n",
      "as: 0.0173\n",
      "\n",
      "TF-IDF for C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 26 - The Statue of Liberty.txt:\n",
      "the: 0.1102\n",
      "statue: 0.0574\n",
      "of: 0.0508\n",
      "her: 0.0430\n",
      "liberty: 0.0430\n",
      "a: 0.0339\n",
      "hand: 0.0287\n",
      "torch: 0.0287\n",
      "in: 0.0254\n",
      "is: 0.0254\n",
      "\n",
      "TF-IDF for C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 26 - The Taj Mahal.txt:\n",
      "the: 0.0862\n",
      "mahal: 0.0511\n",
      "taj: 0.0438\n",
      "is: 0.0388\n",
      "of: 0.0388\n",
      "a: 0.0302\n",
      "and: 0.0302\n",
      "in: 0.0259\n",
      "to: 0.0259\n",
      "world: 0.0222\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "# Read files\n",
    "files = [r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 26 - The Eiffel Tower.txt\", r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 26 - The Statue of Liberty.txt\",r\"C:\\Users\\Vraj Shah\\OneDrive\\Desktop\\Exp 26 - The Taj Mahal.txt\"]\n",
    "documents = []\n",
    "for file in files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        documents.append(f.read().lower())\n",
    "\n",
    "# Tokenize\n",
    "def tokenize(text):\n",
    "    return text.replace('.', '').replace(',', '').split()\n",
    "\n",
    "tokenized_docs = [tokenize(doc) for doc in documents]\n",
    "\n",
    "# Build Vocabulary\n",
    "vocab = sorted(set(word for doc in tokenized_docs for word in doc))\n",
    "\n",
    "# Term Frequency (TF)\n",
    "def compute_tf(doc):\n",
    "    tf = {}\n",
    "    for word in vocab:\n",
    "        tf[word] = doc.count(word) / len(doc)\n",
    "    return tf\n",
    "\n",
    "tfs = [compute_tf(doc) for doc in tokenized_docs]\n",
    "\n",
    "# Inverse Document Frequency (IDF)\n",
    "def compute_idf():\n",
    "    idf = {}\n",
    "    N = len(tokenized_docs)\n",
    "    for word in vocab:\n",
    "        df = sum(word in doc for doc in tokenized_docs)\n",
    "        idf[word] = math.log((N + 1) / (df + 1)) + 1  # smoothing\n",
    "    return idf\n",
    "\n",
    "idf = compute_idf()\n",
    "\n",
    "# TF-IDF\n",
    "tfidfs = []\n",
    "for tf in tfs:\n",
    "    tfidf = {word: tf[word] * idf[word] for word in vocab}\n",
    "    tfidfs.append(tfidf)\n",
    "\n",
    "# Display results\n",
    "for i, tfidf in enumerate(tfidfs):\n",
    "    print(f\"\\nTF-IDF for {files[i]}:\")\n",
    "    sorted_words = sorted(tfidf.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:  # Top 10 words\n",
    "        print(f\"{word}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99fd0c8-3388-493d-8245-581e6882b3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
